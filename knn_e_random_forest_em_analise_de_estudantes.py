# -*- coding: utf-8 -*-
"""Knn e Random Forest em Analise de  Estudantes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15TEHkKufJWQiD_7bR-_Dy6eQ_PQ5aJYJ

Integrantes: Vitor Risso Parisi - Iago Vinicius Ribeiro Siqueira - Vinicius Daniel Dalarmelina Moreira


Tema: Taxa de aprovação dos alunos

Problema: Quais atributos influenciam na nota final dos alunos, afim de incentivar uma melhora.


Estes dados abordam o aproveitamento dos alunos do ensino secundário de duas escolas portuguesas. Os atributos de dados incluem notas dos alunos, características demográficas, sociais e relacionadas à escola) e foram coletados por meio de relatórios e questionários escolares. São fornecidos dois conjuntos de dados relativos ao desempenho em duas disciplinas distintas: Matemática (mat) e Língua Portuguesa (por). Em [Cortez e Silva, 2008], os dois conjuntos de dados foram modelados sob classificação binária / cinco níveis e tarefas de regressão.
"""

# Importanto as bibliotecas Python necessarias ao experimento
# Manipulacao matricial e visualizacao grafica
#--------------------------------------------------
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Carregando a base de dados em um objeto DataFrame pertencente a biblioteca Pandas
# O arquivo .csv esta disponivel para download no Google Classroom. 
localDataEndereco = "/content/student.csv" 
df = pd.read_csv(localDataEndereco)

"""O primeiro passo de qualquer EDA é saber a dimensão da base:"""

# Exibindo  dimensao da base de dados
print("Dimensão dos dados:")
print("Linhas (Instâncias):{}".format(df.shape[0]))
print("Colunas (Atributos):{}".format(df.shape[1]))

"""Foi demonstrado as cinco primeiras instâncias da base de dados para a inspeção e obtenção de conhecimento sobre os dados."""

# Apresenta, de forma completa, as cinco primeiras instâncias da base de dados.
df.head()

"""# Transformação e criação de Features

Foi realizado transformaçoes de variáveis textuais binárias para números binários.
"""

df["schoolsup"]=df["schoolsup"].map({'no':0,'yes':1}).astype(int)
df["famsup"]=df["famsup"].map({'no':0,'yes':1}).astype(int)
df["paid"]=df["paid"].map({'no':0,'yes':1}).astype(int)
df["activities"]=df["activities"].map({'no':0,'yes':1}).astype(int)
df["nursery"]=df["nursery"].map({'no':0,'yes':1}).astype(int)
df["higher"]=df["higher"].map({'no':0,'yes':1}).astype(int)
df["internet"]=df["internet"].map({'no':0,'yes':1}).astype(int)
df["romantic"]=df["romantic"].map({'no':0,'yes':1}).astype(int)
df["famsize"]=df["famsize"].map({'LE3':0,'GT3':1}).astype(int)
df["Pstatus"]=df["Pstatus"].map({'A':0,'T':1}).astype(int)

#df["address"]=df["address"].map({'U':0,'R':1}).astype(int)
#df["guardian"]=df["guardian"].map({'mother':0,'father':1, 'other':2}).astype(int)
#df["Mjob"]=df["Mjob"].map({'at_home':0,'health':1, 'services':2, 'teacher':3, 'other': 4}).astype(int)
#df["Fjob"]=df["Fjob"].map({'at_home':0,'health':1, 'services':2, 'teacher':3, 'other': 4}).astype(int)
#df["reason"]=df["reason"].map({'home':0,'course':1, 'reputation':2,'other': 3}).astype(int)
#df["sex"]=df["sex"].map({'F':0,'M':1}).astype(int)
## Apresentando novamente os dados com as coluna alteradas :

df.head()

"""Foi adicionado uma featuares artificial denominada "mediaFinal" que cálcula a média das notas G1, G2 e G3 de cada estudante para a criação de uma nova features artificial denominada "target" onde mediaFinal >= 12 é 1 e < 12 é 0.


"""

notasEntrada = df.drop(['school', 'sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob','Fjob','reason','guardian','traveltime','studytime','failures','schoolsup','famsup','paid','activities','nursery','higher','internet','romantic','famrel','freetime','goout','Dalc','Walc','health','absences'], axis=1)
dadosEntrada = df
dadosEntrada['mediaFinal'] = notasEntrada.mean(axis=1)
#dadosEntrada['mediana'] = notasEntrada.median(axis=1)
#dadosEntrada['mediaHarmonica'] = hmean(notasEntrada.iloc[:, 0:2], axis=1)
#dadosEntrada['mediaGeometrica'] = gmean(notasEntrada.iloc[:, 0:2], axis=1) 
#dadosEntrada['desvioPadrao'] = notasEntrada.std(axis=1)
#dadosEntrada['variancia'] = notasEntrada.var(axis=1)
#dadosEntrada['coeficienteVariacao'] = 100 * notasEntrada.std(axis=1)/notasEntrada.mean(axis=1)
#dadosEntrada['curtose'] = notasEntrada.kurtosis(axis=1)
#dadosEntrada['assimetria'] = notasEntrada.skew(axis=1)
dadosEntrada.head()

"""Criando a feature artificial target para determinar se o aluno foi aprovado/reprovado."""

dadosEntrada['target'] = 0
for i in range(649):
  if (dadosEntrada['mediaFinal'][i]>=12):
      dadosEntrada['target'][i] = 1
  else:
      dadosEntrada['target'][i] = 0
dadosEntrada.head()

"""Foi realizado uma transformação de variáveis categóricas em variáveis numéricas para aulixiar na manipulação dos dados."""

#pd.get_dummies(df, columns=["address"]).head()
#pd.get_dummies(df, columns=["guardian"]).head()
#pd.get_dummies(df, columns=["Mjob"]).head()
#pd.get_dummies(df, columns=["Fjob"]).head()
#pd.get_dummies(df, columns=["reason"]).head()
#dadosEntrada = pd.get_dummies(dadosEntrada, columns=["sex"]).head()
df_dum = pd.get_dummies(dadosEntrada, columns=["address", "guardian","Mjob","Fjob","reason","sex"], prefix=["address", "guardian","Mjob","Fjob","reason","sex"])
#df["address"] = df["address"].astype('category')
#df.dtypes
#df["address_cat"] = df["address"].cat.codes
df_dum.head()

"""# Correlação das variáveis / Mapa de calor

Foi calculado o coeficiente de correlação entre todas as variáveis para visualizar quais váriaveis tem correlação positiva na coluna "mediaFinal".
"""

#Calculando o coeificiente de correlação entre algumas variáveis da base de dados;

df_dum.corr()
#Apresentando a correlação através de um mapa de calor.
f, ax = plt.subplots(figsize=(30, 30))
plt.title('Correção de Pearson - HeatMap')

sns.heatmap(df_dum.corr(),linewidths=0.7,vmax=1.0, square=True, annot=True)

"""* Medu 0.25
* Fedu 0.20
* traveltime -0.18
* studytime 0.21
* failures -0.32
* higher 0.30
* internet 0.15
* dalc -0.22
* walc -0.19
* absences -0.17
* address_R -0.18
* address_U 0.18
* mjob_at_home -0.18
* fjob_teacher 0.14
* reason_reputation 0.15

# Features com correlação >0,15 e <-0,15

Divisão das variáveis de entrada e target e train_test_split.
"""

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split


saidaDesejada = df_dum['target']


#features correlacao >0.15 e <-0.15
dadosEntrada04=df_dum.drop(['age','sex_F','sex_M','target','mediaFinal','nursery','school','G1','G2','G3','famsize','Pstatus','schoolsup','Mjob_health','Mjob_teacher','famsup','paid','activities','romantic','famrel','freetime','goout','health','guardian_father','guardian_mother','guardian_other','Mjob_other','Mjob_services','Fjob_at_home','Fjob_health','Fjob_other','Fjob_services','reason_course','reason_home','reason_other'], axis=1)
dadosEntrada05=df_dum.drop(['age','sex_F','sex_M','target','mediaFinal','nursery','school','G2','G3','famsize','Pstatus','schoolsup','Mjob_health','Mjob_teacher','famsup','paid','activities','romantic','famrel','freetime','goout','health','guardian_father','guardian_mother','guardian_other','Mjob_other','Mjob_services','Fjob_at_home','Fjob_health','Fjob_other','Fjob_services','reason_course','reason_home','reason_other'], axis=1)

dadosEntrada_train, dadosEntrada_test, saidaDesejada_train, saidaDesejada_test = train_test_split(dadosEntrada05, saidaDesejada, test_size=0.3)
dadosEntrada05.head()

"""KNN


"""

from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, precision_score

knn = KNeighborsClassifier(n_neighbors=24, metric='euclidean')
knn.fit(dadosEntrada_train, saidaDesejada_train)
classificacaoKnn = knn.predict(dadosEntrada_test)

k_list = list(range(1,31))
p_list = [1,2]
w_list = ['uniform','distance']
parametros = dict(n_neighbors=k_list, weights=w_list, p=p_list)
grid = GridSearchCV(knn, parametros, cv=5,  scoring='accuracy')
grid.fit(dadosEntrada_train, saidaDesejada_train)
print(f"Melhores parametros {grid.best_estimator_}")

knn = KNeighborsClassifier( metric='euclidean',n_neighbors=10 ,weights='distance')
knn.fit(dadosEntrada_train, saidaDesejada_train)
classificacaoKnn = knn.predict(dadosEntrada_test)

#Calculando as metricas: Acurácia, Recall, Precision, f1 Score
accuracy_test = accuracy_score(saidaDesejada_test, classificacaoKnn)
recall_test = recall_score(saidaDesejada_test, classificacaoKnn)
precision_test = precision_score(saidaDesejada_test, classificacaoKnn)
f1_test = f1_score(saidaDesejada_test, classificacaoKnn)
print('------------------------------')
print('------------------------------')
print('Acurácia: ', accuracy_test)
print('Recall: ', recall_test)
print('Precision: ', precision_test)
print('f1 Score: ', f1_test)

#Gera a matriz de confusão no formato grafico
confusionMatrix2 = confusion_matrix(saidaDesejada_test,classificacaoKnn)
sns.heatmap(confusionMatrix2,annot=True,fmt="d")

print('------------------------------')
print('------------------------------')
print('--- Matriz de Confusão ---')
pd.DataFrame(confusion_matrix(saidaDesejada_test, classificacaoKnn),
             index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])

"""RANDOM FOREST"""

from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, precision_score
from sklearn.ensemble import RandomForestClassifier
instanciaRandonForest=RandomForestClassifier(max_depth=6,n_estimators=500, random_state = 11850)
instanciaRandonForest.fit(dadosEntrada_train,saidaDesejada_train)
classificacaoRandomForest_BC=instanciaRandonForest.predict(dadosEntrada_test)

#Calculando as metricas: Acurácia, Recall, Precision, f1 Score
accuracy_test = accuracy_score(saidaDesejada_test, classificacaoRandomForest_BC)
recall_test = recall_score(saidaDesejada_test, classificacaoRandomForest_BC)
precision_test = precision_score(saidaDesejada_test, classificacaoRandomForest_BC)
f1_test = f1_score(saidaDesejada_test, classificacaoRandomForest_BC)
print('------------------------------')
print('------------------------------')
print('Acurácia: ', accuracy_test)
print('Recall: ', recall_test)
print('Precision: ', precision_test)
print('f1 Score: ', f1_test)

#Gera a matriz de confusão no formato grafico
confusionMatrix2 = confusion_matrix(saidaDesejada_test,classificacaoRandomForest_BC)
sns.heatmap(confusionMatrix2,annot=True,fmt="d")

print('------------------------------')
print('------------------------------')
print('--- Matriz de Confusão ---')
pd.DataFrame(confusion_matrix(saidaDesejada_test, classificacaoRandomForest_BC),
             index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])

"""# Features com correlaçao >0,15 e <-0,15 e que possam ser incentivadas

Divisão das variáveis de entrada e target e train_test_split.
"""

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split


saidaDesejada = df_dum['target']

#features correlacao >0.15 e <-0.15 influenciaveis 
dadosEntrada11=df_dum.drop(['age','target','mediaFinal','nursery','address_R','address_U', 'Mjob_other','sex_F','sex_M','school','G1','G2','G3','famsize','Pstatus','Medu','Fedu','failures','schoolsup','famsup','paid','activities','romantic','famrel','freetime','goout','health','guardian_father','guardian_mother','guardian_other','Mjob_services','Mjob_teacher','Mjob_health','Mjob_at_home','Fjob_at_home','Fjob_health','Fjob_other','Fjob_services','Fjob_teacher','reason_course','reason_home','reason_other','reason_reputation'], axis=1)
dadosEntrada12=df_dum.drop(['age','target','mediaFinal','nursery','address_R','address_U', 'Mjob_other','sex_F','sex_M','school','G2','G3','famsize','Pstatus','Medu','Fedu','failures','schoolsup','famsup','paid','activities','romantic','famrel','freetime','goout','health','guardian_father','guardian_mother','guardian_other','Mjob_services','Mjob_teacher','Mjob_health','Mjob_at_home','Fjob_at_home','Fjob_health','Fjob_other','Fjob_services','Fjob_teacher','reason_course','reason_home','reason_other','reason_reputation'], axis=1)


dadosEntrada_train, dadosEntrada_test, saidaDesejada_train, saidaDesejada_test = train_test_split(dadosEntrada12, saidaDesejada, test_size=0.3)
dadosEntrada12.head()

"""KNN


"""

from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, precision_score

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(dadosEntrada_train, saidaDesejada_train)
classificacaoKnn = knn.predict(dadosEntrada_test)

k_list = list(range(1,31))
p_list = [1,2]
w_list = ['uniform','distance']

parametros = dict(n_neighbors=k_list, weights=w_list, p=p_list)
grid = GridSearchCV(knn, parametros, cv=5,  scoring='accuracy')
grid.fit(dadosEntrada_train, saidaDesejada_train)
print(f"Melhores parametros {grid.best_estimator_}")

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, precision_score
knn = KNeighborsClassifier( n_neighbors=21, metric='minkowski',weights='distance' )
knn.fit(dadosEntrada_train, saidaDesejada_train)
classificacaoKnn = knn.predict(dadosEntrada_test)

#Calculando as metricas: Acurácia, Recall, Precision, f1 Score
accuracy_test = accuracy_score(saidaDesejada_test, classificacaoKnn)
recall_test = recall_score(saidaDesejada_test, classificacaoKnn)
precision_test = precision_score(saidaDesejada_test, classificacaoKnn)
f1_test = f1_score(saidaDesejada_test, classificacaoKnn)
print('------------------------------')
print('------------------------------')
print('Acurácia: ', accuracy_test)
print('Recall: ', recall_test)
print('Precision: ', precision_test)
print('f1 Score: ', f1_test)

#Gera a matriz de confusão no formato grafico
confusionMatrix2 = confusion_matrix(saidaDesejada_test,classificacaoKnn)
sns.heatmap(confusionMatrix2,annot=True,fmt="d")

print('------------------------------')
print('------------------------------')
print('--- Matriz de Confusão ---')
pd.DataFrame(confusion_matrix(saidaDesejada_test, classificacaoKnn),
             index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])

"""RANDOM FOREST"""

from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, precision_score
from sklearn.ensemble import RandomForestClassifier
instanciaRandonForest=RandomForestClassifier(max_depth=6,n_estimators=500, random_state = 11850)
instanciaRandonForest.fit(dadosEntrada_train,saidaDesejada_train)
classificacaoRandomForest_BC=instanciaRandonForest.predict(dadosEntrada_test)

#Calculando as metricas: Acurácia, Recall, Precision, f1 Score
accuracy_test = accuracy_score(saidaDesejada_test, classificacaoRandomForest_BC)
recall_test = recall_score(saidaDesejada_test, classificacaoRandomForest_BC)
precision_test = precision_score(saidaDesejada_test, classificacaoRandomForest_BC)
f1_test = f1_score(saidaDesejada_test, classificacaoRandomForest_BC)
print('------------------------------')
print('------------------------------')
print('Acurácia: ', accuracy_test)
print('Recall: ', recall_test)
print('Precision: ', precision_test)
print('f1 Score: ', f1_test)

#Gera a matriz de confusão no formato grafico
confusionMatrix2 = confusion_matrix(saidaDesejada_test,classificacaoRandomForest_BC)
sns.heatmap(confusionMatrix2,annot=True,fmt="d")

print('------------------------------')
print('------------------------------')
print('--- Matriz de Confusão ---')
pd.DataFrame(confusion_matrix(saidaDesejada_test, classificacaoRandomForest_BC),
             index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])